import os
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import GridSearchCV

# pip install pandas numpy matplotlib scikit-learn

# üß† –ß—Ç–æ —Ç–∞–∫–æ–µ DecisionTreeClassifier
# DecisionTreeClassifier ‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö,
# —Ç.–µ. —á—Ç–æ–±—ã –æ—Ç–Ω–µ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç—ã –∫ –æ–¥–Ω–æ–º—É –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞—Ä–∞–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
# (–Ω–∞–ø—Ä–∏–º–µ—Ä, "poor", "good", "excellent").

# üìä –ò–¥–µ—è
# –ê–ª–≥–æ—Ä–∏—Ç–º —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π:
# –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø—Ä–∏–∑–Ω–∞–∫, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –¥–∞–Ω–Ω—ã–µ –ª—É—á—à–µ –≤—Å–µ–≥–æ –¥–µ–ª—è—Ç—Å—è –Ω–∞ –∫–ª–∞—Å—Å—ã.
# –î–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞:
# –õ–∏—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å, –∏–ª–∏
# –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ / –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è).

—Åurrent_dir = os.path.dirname(__file__)  # –ü–∞–ø–∫–∞, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è .py —Ñ–∞–π–ª
# file_path_read_train = os.path.join(—Åurrent_dir, "synthetic_200_rows_with_logic_filled.csv")
# file_path_read_to_predict = os.path.join(—Åurrent_dir, "to_predict_filled.csv")
# file_path_write = os.path.join(—Åurrent_dir, "to_predict_with_y.csv")

file_path_read_train = os.path.join(—Åurrent_dir, "winequality_red_train.csv")
file_path_read_to_predict = os.path.join(—Åurrent_dir, "winequality_red_to_predict.csv")
file_path_write = os.path.join(—Åurrent_dir, "winequality_red_to_predict_with_y.csv")

# üì• –ó–∞–≥—Ä—É–∑–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
df = pd.read_csv(file_path_read_train)

# üìå –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ X (–ø—Ä–∏–∑–Ω–∞–∫–∏) –∏ y (—Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫)
X = df.drop(columns=["quality"])
y = df["quality"]

# üéØ –ü—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫–∏–µ –∫–ª–∞—Å—Å—ã –µ—Å—Ç—å
print("üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –≤ y:", y.unique())
print("üì¶ –†–∞–∑–º–µ—Ä X:", X.shape)
print("üéØ –†–∞–∑–º–µ—Ä y:", y.shape)

# üîÄ –†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train –∏ test
# –®–∞–≥ 1. –û—Ç–¥–µ–ª—è–µ–º test
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=4, stratify=y
)

# –®–∞–≥ 2. –î–µ–ª–∏–º X_temp –Ω–∞ train –∏ validation
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.2, random_state=4, stratify=y_temp
)

# –ü—Ä–æ–≤–µ—Ä–∏–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤
print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_train:")
print(y_train.value_counts(normalize=True).sort_index())

print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
print(f"–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_val.shape}")
print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape}")


# 1. –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
categorical_features = []
numeric_features = ["fixed acidity", "volatile acidity", "citric acid", "residual sugar",
            "chlorides", "free sulfur dioxide", "total sulfur dioxide" , "density",
            "pH", "sulphates", "alcohol"]

# 2. –ü–æ—Å—Ç—Ä–æ–∏–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_features),
    ("cat", OneHotEncoder(drop='first'), categorical_features)
])

# 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
X_train_prepared = preprocessor.fit_transform(X_train)
X_val_prepared = preprocessor.transform(X_val)
X_test_prepared = preprocessor.transform(X_test)

# 4. –û–±—É—á–∏–º –º–æ–¥–µ–ª—å
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞
param_grid = {
    "max_depth": [2, 4, 6, 8, 10, 15, 20],
    "min_samples_leaf": [1, 5, 10, 20]
}

# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
tree = DecisionTreeClassifier(random_state=4)

# GridSearchCV: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
grid_search = GridSearchCV(tree, param_grid, cv=3, scoring="accuracy")
grid_search.fit(X_train_prepared, y_train)

# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
best_model = grid_search.best_estimator_
y_val_pred = best_model.predict(X_val_prepared)
val_accuracy = accuracy_score(y_val, y_val_pred)

print("üéØ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:", grid_search.best_params_)
print(f"‚úÖ Accuracy (cross-validation): {grid_search.best_score_:.4f}")

# –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ validation:
y_val_pred = best_model.predict(X_val_prepared)
val_accuracy = accuracy_score(y_val, y_val_pred)
print(f"üß™ Accuracy –Ω–∞ validation set: {val_accuracy:.4f}")

# üìä –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
feature_names_num = preprocessor.named_transformers_["num"].get_feature_names_out(numeric_features)

if categorical_features:
    feature_names_cat = preprocessor.named_transformers_["cat"].get_feature_names_out(categorical_features)
else:
    feature_names_cat = []

all_feature_names = list(feature_names_num) + list(feature_names_cat)

importances = best_model.feature_importances_
indices = sorted(range(len(importances)), key=lambda i: importances[i], reverse=True)

print("\nüî¨ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
for i in indices:
    print(f"{all_feature_names[i]}: {importances[i]:.4f}")

# 5. –ü—Ä–µ–¥—Å–∫–∞–∂–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
y_pred = best_model.predict(X_test_prepared)

# 6. –û—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ
test_accuracy = accuracy_score(y_test, y_pred)
print("\nüéØ Accuracy –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:", test_accuracy)
print("\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
print(confusion_matrix(y_test, y_pred))

print("\nüßæ –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
print(classification_report(y_test, y_pred, zero_division=0))

# üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
df_to_predict = pd.read_csv(file_path_read_to_predict)

# üéØ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
y_true = df_to_predict["quality_True"]

# üßπ –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–±–µ–∑ y)
X_to_predict = df_to_predict.drop(columns=["quality_True"])

# ‚ôªÔ∏è –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–µ–º –∂–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º!)
X_to_predict_prepared = preprocessor.transform(X_to_predict)

# üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = best_model.predict(X_to_predict_prepared)

# üéØ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å y_True)
accuracy_on_to_predict = accuracy_score(y_true, y_pred)
print("üìä Accuracy –Ω–∞ to_predict_multiclass.csv:", accuracy_on_to_predict)
print("\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
print(confusion_matrix(y_true, y_pred))
print("\nüßæ –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
print(classification_report(y_true, y_pred, zero_division=0))

# üìù –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ñ–∞–π–ª
df_to_predict["quality"] = y_pred
df_to_predict.to_csv(file_path_write, index=False)
print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {file_path_write}")

# üìâ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞
plt.figure(figsize=(20, 10))
plot_tree(best_model,
          feature_names=preprocessor.get_feature_names_out(),
          class_names=[str(c) for c in best_model.classes_],
          filled=True,
          rounded=True,
          fontsize=10)
plt.title("Decision Tree Classifier")
plt.tight_layout()

# üîπ 1. num__Score <= 0.022
# –≠—Ç–æ —É—Å–ª–æ–≤–∏–µ, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ä–∞–∑–≤–µ—Ç–≤–ª–µ–Ω–∏–µ.
# num__Score ‚Äî –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫ Score, –ø—Ä–æ—à–µ–¥—à–∏–π —á–µ—Ä–µ–∑ StandardScaler (–ø–æ—ç—Ç–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –æ–∫–æ–ª–æ –Ω—É–ª—è).
# <= 0.022 ‚Äî —ç—Ç–æ –ø–æ—Ä–æ–≥:
# –ï—Å–ª–∏ Score –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–µ–Ω 0.022, –¥–∞–Ω–Ω—ã–µ –∏–¥—É—Ç –≤–ª–µ–≤–æ.
# –ï—Å–ª–∏ –±–æ–ª—å—à–µ, ‚Äî –≤–ø—Ä–∞–≤–æ.
# –í–∞–∂–Ω–æ: –ø—Ä–µ—Ñ–∏–∫—Å num__ –≤–∑—è—Ç –∏–∑ ColumnTransformer ‚Äî —ç—Ç–æ –∏–º—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ç–æ—Ä–∞ "num" (—á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏), –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–µ –∫ –∏–º–µ–Ω–∏ –∫–æ–ª–æ–Ω–∫–∏.

# üîπ 2. gini = 0.697
# –≠—Ç–æ –∏–Ω–¥–µ–∫—Å –î–∂–∏–Ω–∏ ‚Äî –º–µ—Ä–∞ "–Ω–µ–æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏" –≤—ã–±–æ—Ä–∫–∏ –≤ —ç—Ç–æ–º —É–∑–ª–µ.
# –ó–Ω–∞—á–µ–Ω–∏–µ 0 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞.
# –ß–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º —Å–º–µ—à–∞–Ω–Ω–µ–µ –∫–ª–∞—Å—Å—ã.
# –ó–Ω–∞—á–µ–Ω–∏–µ 0.697 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤ —ç—Ç–æ–º —É–∑–ª–µ –¥–∞–Ω–Ω—ã–µ —Å–∏–ª—å–Ω–æ –ø–µ—Ä–µ–º–µ—à–∞–Ω—ã –ø–æ –∫–ª–∞—Å—Å–∞–º.

# üîπ 3. samples = 160
# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ (—Å—Ç—Ä–æ–∫) –≤ —ç—Ç–æ–º —É–∑–ª–µ –¥–µ—Ä–µ–≤–∞ ‚Äî 160 —Å—Ç—Ä–æ–∫.

# üîπ 4. value = [54, 19, 62, 25]
# –≠—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º:
# –í —ç—Ç–æ–º —É–∑–ª–µ:
# 54 –ø—Ä–∏–º–µ—Ä–∞ –∫–ª–∞—Å—Å–∞ "average"
# 19 –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–ª–∞—Å—Å–∞ "excellent"
# 62 –ø—Ä–∏–º–µ—Ä–∞ –∫–ª–∞—Å—Å–∞ "good"
# 25 –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–ª–∞—Å—Å–∞ "poor"

# –ü–æ—Ä—è–¥–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç class_names, –∫–æ—Ç–æ—Ä—ã–µ —Ç—ã –ø–µ—Ä–µ–¥–∞–≤–∞–ª –≤ plot_tree(...).
# üîπ 5. class = "good"
# –≠—Ç–æ "–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å" –¥–ª—è —É–∑–ª–∞.
# –¢–æ –µ—Å—Ç—å –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç –ø–æ–ø–∞–¥–µ—Ç –≤ —ç—Ç–æ—Ç —É–∑–µ–ª, –º–æ–¥–µ–ª—å –ø—Ä–∏—Å–≤–æ–∏—Ç –µ–º—É
# –∫–ª–∞—Å—Å "good", –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ —Å–∞–º—ã–π —á–∞—Å—Ç—ã–π –∫–ª–∞—Å—Å –≤ —ç—Ç–æ–º —É–∑–ª–µ (62 –∏–∑ 160).
# ‚úèÔ∏è –í–∏–∑—É–∞–ª—å–Ω–æ:
# –¶–≤–µ—Ç —É–∑–ª–∞ ‚Äî –æ—Ç—Ä–∞–∂–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: —á–µ–º —è—Ä—á–µ, —Ç–µ–º –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–µ–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ –∫–ª–∞—Å—Å—É.
# –ß–µ–º –±–ª–µ–¥–Ω–µ–µ, —Ç–µ–º —Å–º–µ—à–∞–Ω–Ω–µ–µ –∫–ª–∞—Å—Å—ã –≤ —É–∑–ª–µ.

# üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
output_path = os.path.join(—Åurrent_dir, "decision_tree_decision_tree.png")
plt.savefig(output_path, dpi=300)

plt.show()

print("\nDecision Tree")
print("üìä Accuracy –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö:")
print(f"Validation:  {val_accuracy:.4f}")
print(f"Test:        {test_accuracy:.4f}")
print(f"Final:        {accuracy_on_to_predict:.4f}")

# Decision Tree
# üìä Accuracy –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö:
# Validation:  0.5887
# Test:        0.5764
# Final:        0.5437