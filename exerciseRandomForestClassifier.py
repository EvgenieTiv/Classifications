import os
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.preprocessing import PolynomialFeatures

# conda install pandas numpy matplotlib scikit-learn

current_dir = os.path.dirname(__file__)  # –ü–∞–ø–∫–∞, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è .py —Ñ–∞–π–ª
# file_path_read_train = os.path.join(—Åurrent_dir, "synthetic_200_rows_with_logic_filled.csv")
# file_path_read_to_predict = os.path.join(—Åurrent_dir, "to_predict_filled.csv")
# file_path_write = os.path.join(—Åurrent_dir, "to_predict_with_y.csv")

file_path_read_train = os.path.join(current_dir, "winequality_red_train.csv")
file_path_read_to_predict = os.path.join(current_dir, "winequality_red_to_predict.csv")
file_path_write = os.path.join(current_dir, "winequality_red_to_predict_with_y.csv")

# üì• –ó–∞–≥—Ä—É–∑–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
df = pd.read_csv(file_path_read_train)

# üìå –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ X (–ø—Ä–∏–∑–Ω–∞–∫–∏) –∏ y (—Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫)
X = df.drop(columns=["quality"])
y = df["quality"]

# üéØ –ü—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫–∏–µ –∫–ª–∞—Å—Å—ã –µ—Å—Ç—å
print("üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –≤ y:", y.unique())
print("üì¶ –†–∞–∑–º–µ—Ä X:", X.shape)
print("üéØ –†–∞–∑–º–µ—Ä y:", y.shape)

# üîÄ –†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train –∏ test
# –®–∞–≥ 1. –û—Ç–¥–µ–ª—è–µ–º test
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=4, stratify=y   # ‚¨ÖÔ∏è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ train –∏ test
)

# –®–∞–≥ 2. –î–µ–ª–∏–º X_temp –Ω–∞ train –∏ validation
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.2, random_state=4, stratify=y_temp   # ‚¨ÖÔ∏è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ train –∏ test
)

# –ü—Ä–æ–≤–µ—Ä–∏–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤
print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_train:")
print(y_train.value_counts(normalize=True).sort_index())

print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
print(f"–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_val.shape}")
print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape}")

# 1. –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
categorical_features = []
numeric_features = ["fixed acidity", "volatile acidity", "citric acid", "residual sugar",
            "chlorides", "free sulfur dioxide", "total sulfur dioxide" , "density",
            "pH", "sulphates", "alcohol"]

# 2. –ü–æ—Å—Ç—Ä–æ–∏–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_features),
    ("cat", OneHotEncoder(drop='first'), categorical_features)
])

# 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
X_train_prepared = preprocessor.fit_transform(X_train)
X_val_prepared = preprocessor.transform(X_val)
X_test_prepared = preprocessor.transform(X_test)  # ‚úÖ –Ω–∞—Å—Ç–æ—è—â–µ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ

# New start
# poly = PolynomialFeatures(degree=3, include_bias=False)
# X_train_prepared = poly.fit_transform(X_train_prepared)
# X_val_prepared = poly.transform(X_val_prepared)
# X_test_prepared = poly.transform(X_test_prepared)

# –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è PolynomialFeatures
# all_feature_names = poly.get_feature_names_out()
# New end

# Grid Search —Å 5-–∫—Ä–∞—Ç–Ω–æ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
# estimator	model	–≠—Ç–æ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
# param_grid	param_grid	–°–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞
# cv=5	–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è	–î–µ–ª–∏—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ 5 —á–∞—Å—Ç–µ–π ‚Üí 4 –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ, 1 –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É (–∏ —Ç–∞–∫ 5 —Ä–∞–∑)
# scoring='r2'	–¶–µ–ª–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞	–ö–∞–∫ –≤—ã–±–∏—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å. 'r2' = –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏
# verbose=1	–í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å	–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å (0 ‚Äî –º–æ–ª—á–∞—Ç—å, 1 ‚Äî –Ω–µ–º–Ω–æ–≥–æ, 2 ‚Äî –ø–æ–¥—Ä–æ–±–Ω–æ)
# n_jobs=-1	–í—Å–µ —è–¥—Ä–∞	–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ ‚Üí –±—ã—Å—Ç—Ä–µ–µ

# –°–µ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
param_grid = {
    "n_estimators": [50, 75, 100, 200],
    "max_depth": [None, 5, 10],
    "min_samples_leaf": [1, 3, 5],
    "bootstrap": [True, False]  # ‚¨ÖÔ∏è –Ω–æ–≤–∏–Ω–∫–∞
}

# n_jobs=-1	–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ CPU —è–¥—Ä–∞	–£—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –∑–∞ —Å—á—ë—Ç –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
model = RandomForestClassifier(random_state=4, n_jobs=-1)

grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',  # ‚¨ÖÔ∏è –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    verbose=1,
    n_jobs=-1
)

# –û–±—É—á–µ–Ω–∏–µ
grid_search.fit(X_train_prepared, y_train)

# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
# print("–ú–æ–¥–µ–ª—å –°–ª—É—á–∞–π–Ω–æ–≥–æ –õ–µ—Å–∞")
print("‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", grid_search.best_params_)
print("üìà –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (accuracy, –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è):", grid_search.best_score_)

# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
best_model = grid_search.best_estimator_
y_val_pred = best_model.predict(X_val_prepared)
val_accuracy = accuracy_score(y_val, y_val_pred)

print("üéØ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:", grid_search.best_params_)
print(f"‚úÖ Accuracy (cross-validation): {grid_search.best_score_:.4f}")

# –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ validation:
y_val_pred = best_model.predict(X_val_prepared)
val_accuracy = accuracy_score(y_val, y_val_pred)

print(f"\nüß™ Accuracy –Ω–∞ validation set: {val_accuracy:.4f}")

# üìä –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
# FROM
# feature_names_num = preprocessor.named_transformers_["num"].get_feature_names_out(numeric_features)
#
# if categorical_features:
#     feature_names_cat = preprocessor.named_transformers_["cat"].get_feature_names_out(categorical_features)
# else:
#     feature_names_cat = []
#
# all_feature_names = list(feature_names_num) + list(feature_names_cat)
# TO

importances = best_model.feature_importances_
indices = sorted(range(len(importances)), key=lambda i: importances[i], reverse=True)

# print("\nüî¨ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
# for i in indices:
#     print(f"{all_feature_names[i]}: {importances[i]:.4f}")

# 5. –ü—Ä–µ–¥—Å–∫–∞–∂–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
y_pred = best_model.predict(X_test_prepared)

# 6. –û—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ
test_accuracy = accuracy_score(y_test, y_pred)
print("\nüéØ Accuracy –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:", test_accuracy)
print("\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
print(confusion_matrix(y_test, y_pred))

print("\nüßæ –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
print(classification_report(y_test, y_pred, zero_division=0))

# üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
df_to_predict = pd.read_csv(file_path_read_to_predict)

# üéØ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
y_true = df_to_predict["quality_True"]

# üßπ –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–±–µ–∑ y)
X_to_predict = df_to_predict.drop(columns=["quality_True"])

# ‚ôªÔ∏è –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–µ–º –∂–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º!)
X_to_predict_prepared = preprocessor.transform(X_to_predict)
# New
# X_to_predict_prepared = poly.transform(X_to_predict_prepared)

# üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = best_model.predict(X_to_predict_prepared)

# üéØ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å y_True)
accuracy_on_to_predict = accuracy_score(y_true, y_pred)
print("üìä Accuracy –Ω–∞ to_predict_multiclass.csv:", accuracy_on_to_predict)
print("\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
print(confusion_matrix(y_true, y_pred))
print("\nüßæ –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
print(classification_report(y_true, y_pred))

# üìù –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ñ–∞–π–ª
df_to_predict["quality"] = y_pred
df_to_predict.to_csv(file_path_write, index=False)
print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {file_path_write}")

print("\nRandom forest")
print("üìä Accuracy –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö:")
print(f"Validation:  {val_accuracy:.4f}")
print(f"Test:        {test_accuracy:.4f}")
print(f"Final:        {accuracy_on_to_predict:.4f}")

# Random forest
# üìä Accuracy –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö:
# Validation:  0.6494
# Test:        0.6528
# Final:        0.6438
